# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

import os.path as osp
from bisect import bisect_right

import torch
import torch.utils.data as data
import numpy as np

from .datasets import DATA_LAYERS as registry


@registry.register('LSTRTHUMOS')
@registry.register('LSTRTVSeries')
class LSTRDataLayer(data.Dataset):

    def __init__(self, cfg, phase='train'):
        self.data_root = cfg.DATA.DATA_ROOT
        self.visual_feature = cfg.INPUT.VISUAL_FEATURE   # skeleton feature dir
        self.target_perframe = cfg.INPUT.TARGET_PERFRAME
        split_name = getattr(cfg.DATA, phase.upper() + '_SESSION_SET')
        if isinstance(split_name, str):
            self.sessions = self._load_split(split_name)
        else:
            self.sessions = split_name


        self.long_memory_length = cfg.MODEL.LSTR.LONG_MEMORY_LENGTH
        self.long_memory_sample_rate = cfg.MODEL.LSTR.LONG_MEMORY_SAMPLE_RATE
        self.long_memory_num_samples = cfg.MODEL.LSTR.LONG_MEMORY_NUM_SAMPLES
        self.work_memory_length = cfg.MODEL.LSTR.WORK_MEMORY_LENGTH
        self.work_memory_sample_rate = cfg.MODEL.LSTR.WORK_MEMORY_SAMPLE_RATE

        self.training = phase == 'train'
        self._init_dataset()

    def shuffle(self):
        self._init_dataset()
        
    def _load_split(self, split_name):
        split_file = osp.join(self.data_root, f"{split_name}.txt")
        with open(split_file, "r") as f:
            return [line.strip() for line in f if line.strip()]


    def _init_dataset(self):
        self.inputs = []
        for session in self.sessions:
            target = np.load(
                osp.join(self.data_root, self.target_perframe, session + '.npy')
            )
            seed = np.random.randint(self.work_memory_length) if self.training else 0
            for work_start, work_end in zip(
                range(seed, target.shape[0], self.work_memory_length),
                range(seed + self.work_memory_length, target.shape[0], self.work_memory_length)
            ):
                self.inputs.append([
                    session, work_start, work_end, target[work_start:work_end]
                ])

    def segment_sampler(self, start, end, num_samples):
        indices = np.linspace(start, end, num_samples)
        return np.sort(indices).astype(np.int32)

    def uniform_sampler(self, start, end, num_samples, sample_rate):
        indices = np.arange(start, end + 1)[::sample_rate]
        padding = num_samples - indices.shape[0]
        if padding > 0:
            indices = np.concatenate((np.zeros(padding), indices))
        return np.sort(indices).astype(np.int32)

    def __getitem__(self, index):
        session, work_start, work_end, target = self.inputs[index]

        visual_inputs = np.load(
            osp.join(self.data_root, self.visual_feature, session + '.npy'),
            mmap_mode='r'
        )

        target = target[::self.work_memory_sample_rate]

        work_indices = np.arange(work_start, work_end).clip(0)
        work_indices = work_indices[::self.work_memory_sample_rate]
        work_visual_inputs = visual_inputs[work_indices]

        if self.long_memory_num_samples > 0:
            long_start, long_end = max(0, work_start - self.long_memory_length), work_start - 1
            if self.training:
                long_indices = self.segment_sampler(
                    long_start, long_end, self.long_memory_num_samples
                ).clip(0)
            else:
                long_indices = self.uniform_sampler(
                    long_start, long_end,
                    self.long_memory_num_samples,
                    self.long_memory_sample_rate
                ).clip(0)

            long_visual_inputs = visual_inputs[long_indices]

            memory_key_padding_mask = np.zeros(long_indices.shape[0])
            last_zero = bisect_right(long_indices, 0) - 1
            if last_zero > 0:
                memory_key_padding_mask[:last_zero] = float('-inf')

            fusion_visual_inputs = np.concatenate(
                (long_visual_inputs, work_visual_inputs)
            )
        else:
            fusion_visual_inputs = work_visual_inputs
            memory_key_padding_mask = None

        fusion_visual_inputs = torch.as_tensor(
            fusion_visual_inputs.astype(np.float32)
        )
        target = torch.as_tensor(target.astype(np.float32))
        motion_inputs = fusion_visual_inputs  # 그대로 유지

        if memory_key_padding_mask is not None:
            memory_key_padding_mask = torch.as_tensor(
            memory_key_padding_mask.astype(np.float32))
            return fusion_visual_inputs, motion_inputs, memory_key_padding_mask, target
        else:
            
            return fusion_visual_inputs, motion_inputs, target


    def __len__(self):
        return len(self.inputs)


@registry.register('LSTRBatchInferenceTHUMOS')
@registry.register('LSTRBatchInferenceTVSeries')
class LSTRBatchInferenceDataLayer(data.Dataset):

    def __init__(self, cfg, phase='test'):
        self.data_root = cfg.DATA.DATA_ROOT
        self.visual_feature = cfg.INPUT.VISUAL_FEATURE
        self.target_perframe = cfg.INPUT.TARGET_PERFRAME
        self.sessions = getattr(cfg.DATA, phase.upper() + '_SESSION_SET')

        self.long_memory_length = cfg.MODEL.LSTR.LONG_MEMORY_LENGTH
        self.long_memory_sample_rate = cfg.MODEL.LSTR.LONG_MEMORY_SAMPLE_RATE
        self.long_memory_num_samples = cfg.MODEL.LSTR.LONG_MEMORY_NUM_SAMPLES
        self.work_memory_length = cfg.MODEL.LSTR.WORK_MEMORY_LENGTH
        self.work_memory_sample_rate = cfg.MODEL.LSTR.WORK_MEMORY_SAMPLE_RATE

        assert phase == 'test'

        self.inputs = []
        for session in self.sessions:
            target = np.load(
                osp.join(self.data_root, self.target_perframe, session + '.npy')
            )
            for work_start, work_end in zip(
                range(0, target.shape[0] + 1),
                range(self.work_memory_length, target.shape[0] + 1)
            ):
                self.inputs.append([
                    session, work_start, work_end,
                    target[work_start:work_end],
                    target.shape[0]
                ])

    def uniform_sampler(self, start, end, num_samples, sample_rate):
        indices = np.arange(start, end + 1)[::sample_rate]
        padding = num_samples - indices.shape[0]
        if padding > 0:
            indices = np.concatenate((np.zeros(padding), indices))
        return np.sort(indices).astype(np.int32)

    def __getitem__(self, index):
        session, work_start, work_end, target, num_frames = self.inputs[index]

        visual_inputs = np.load(
            osp.join(self.data_root, self.visual_feature, session + '.npy'),
            mmap_mode='r'
        )

        target = target[::self.work_memory_sample_rate]

        work_indices = np.arange(work_start, work_end).clip(0)
        work_indices = work_indices[::self.work_memory_sample_rate]
        work_visual_inputs = visual_inputs[work_indices]

        if self.long_memory_num_samples > 0:
            long_start, long_end = max(0, work_start - self.long_memory_length), work_start - 1
            long_indices = self.uniform_sampler(
                long_start, long_end,
                self.long_memory_num_samples,
                self.long_memory_sample_rate
            ).clip(0)
            long_visual_inputs = visual_inputs[long_indices]

            memory_key_padding_mask = np.zeros(long_indices.shape[0])
            last_zero = bisect_right(long_indices, 0) - 1
            if last_zero > 0:
                memory_key_padding_mask[:last_zero] = float('-inf')

            fusion_visual_inputs = np.concatenate(
                (long_visual_inputs, work_visual_inputs)
            )
        else:
            fusion_visual_inputs = work_visual_inputs
            memory_key_padding_mask = None

        fusion_visual_inputs = torch.as_tensor(
            fusion_visual_inputs.astype(np.float32)
        )
        target = torch.as_tensor(target.astype(np.float32))
        
        motion_inputs = fusion_visual_inputs

        if memory_key_padding_mask is not None:
            memory_key_padding_mask = torch.as_tensor(
            memory_key_padding_mask.astype(np.float32)
            )
            return (
            fusion_visual_inputs,
            motion_inputs,
            memory_key_padding_mask,
            target,
            session,
            work_indices,
            num_frames
            )
        else:
            return (
            fusion_visual_inputs,
            motion_inputs,
            target,
            session,
            work_indices,
            num_frames
        )


    def __len__(self):
        return len(self.inputs)
